{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGA DE DADOS ORIGINAIS \n",
    "informando a carga de dados originais e separando entre características e classe alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definido o título da colunas \n",
    "headers = ['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide',\n",
    "            'total sulfur dioxide','density','pH','sulphates','alcohol','quality']\n",
    "\n",
    "#carga do conjunto de treino\n",
    "file = 'winequality-red.csv'\n",
    "data_train = pd.read_csv(file, sep=';', header=None, names=headers)\n",
    "#data_train.info(verbose=True)\n",
    "\n",
    "#Transfomaçao dos atributos e da classe alvo em matriz\n",
    "X_train_ = np.array(data_train.iloc[:, 0:11])\n",
    "y_train_ = np.array(data_train['quality'])\n",
    "\n",
    "#Separação de treino e validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_, y_train_, train_size = 0.2, random_state=31)\n",
    "\n",
    "#Carga de conjunto de teste\n",
    "file = 'winequality-red.csv'\n",
    "data_test = pd.read_csv(file, sep=';', header=None, names=headers)\n",
    "\n",
    "#Transformação dos atributos e da classe alvo em matriz\n",
    "X_test = np.array(data_test.iloc[:,0:11])\n",
    "y_test = np.array(data_train['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0  fixed acidity  volatile acidity  citric acid  residual sugar  chlorides   \n",
      "1            7.4               0.7            0             1.9      0.076   \n",
      "2            7.8              0.88            0             2.6      0.098   \n",
      "3            7.8              0.76         0.04             2.3      0.092   \n",
      "4           11.2              0.28         0.56             1.9      0.075   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0  free sulfur dioxide  total sulfur dioxide  density    pH  sulphates   \n",
      "1                   11                    34   0.9978  3.51       0.56   \n",
      "2                   25                    67   0.9968   3.2       0.68   \n",
      "3                   15                    54    0.997  3.26       0.65   \n",
      "4                   17                    60    0.998  3.16       0.58   \n",
      "\n",
      "   alcohol  quality  \n",
      "0  alcohol  quality  \n",
      "1      9.4        5  \n",
      "2      9.8        5  \n",
      "3      9.8        5  \n",
      "4      9.8        6  \n",
      "\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0  fixed acidity  volatile acidity  citric acid  residual sugar  chlorides   \n",
      "1            7.4               0.7            0             1.9      0.076   \n",
      "2            7.8              0.88            0             2.6      0.098   \n",
      "3            7.8              0.76         0.04             2.3      0.092   \n",
      "4           11.2              0.28         0.56             1.9      0.075   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0  free sulfur dioxide  total sulfur dioxide  density    pH  sulphates   \n",
      "1                   11                    34   0.9978  3.51       0.56   \n",
      "2                   25                    67   0.9968   3.2       0.68   \n",
      "3                   15                    54    0.997  3.26       0.65   \n",
      "4                   17                    60    0.998  3.16       0.58   \n",
      "\n",
      "   alcohol  quality  \n",
      "0  alcohol  quality  \n",
      "1      9.4        5  \n",
      "2      9.8        5  \n",
      "3      9.8        5  \n",
      "4      9.8        6  \n",
      "\n",
      "['7.7' '0.64' '0.21' '2.2' '0.077' '32' '133' '0.9956' '3.27' '0.45' '9.9']\n",
      "\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#checando de parte dos dados carregados\n",
    "print(data_train.head(), \n",
    "        data_test.head(), \n",
    "        X_train[0], \n",
    "        y_train[0], \n",
    "        sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>97</td>\n",
       "      <td>144</td>\n",
       "      <td>81</td>\n",
       "      <td>92</td>\n",
       "      <td>154</td>\n",
       "      <td>61</td>\n",
       "      <td>145</td>\n",
       "      <td>437</td>\n",
       "      <td>90</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.08</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>67</td>\n",
       "      <td>47</td>\n",
       "      <td>132</td>\n",
       "      <td>156</td>\n",
       "      <td>66</td>\n",
       "      <td>138</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>57</td>\n",
       "      <td>69</td>\n",
       "      <td>139</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity volatile acidity citric acid residual sugar chlorides  \\\n",
       "count           1600             1600        1600           1600      1600   \n",
       "unique            97              144          81             92       154   \n",
       "top              7.2              0.6           0              2      0.08   \n",
       "freq              67               47         132            156        66   \n",
       "\n",
       "       free sulfur dioxide total sulfur dioxide density    pH sulphates  \\\n",
       "count                 1600                 1600    1600  1600      1600   \n",
       "unique                  61                  145     437    90        97   \n",
       "top                      6                   28  0.9972   3.3       0.6   \n",
       "freq                   138                   43      36    57        69   \n",
       "\n",
       "       alcohol quality  \n",
       "count     1600    1600  \n",
       "unique      66       7  \n",
       "top        9.5       5  \n",
       "freq       139     681  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALIZAÇÃO DOS DADOS \n",
    "Como pode ser vistos nas saídas do final da seção as características estão em ordens de grandeza diferentes. Para muitos algoritmos este é um problema que pode levar a modelos inadequados. Para resolver este problema realizaremos a normalização dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação do transformador para normalização\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "norm = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'fixed acidity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [41], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#Normalização das características\u001b[39;00m\n\u001b[0;32m      2\u001b[0m X_train \u001b[39m=\u001b[39m norm\u001b[39m.\u001b[39mfit_transform(X_train)\n\u001b[1;32m----> 3\u001b[0m X_test \u001b[39m=\u001b[39m norm\u001b[39m.\u001b[39;49mfit_transform(X_test)\n\u001b[0;32m      4\u001b[0m X_val \u001b[39m=\u001b[39m norm\u001b[39m.\u001b[39mfit_transform(X_val)\n",
      "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:867\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    868\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:809\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 809\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:844\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[39m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \n\u001b[0;32m    814\u001b[0m \u001b[39mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[39m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    843\u001b[0m first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 844\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    845\u001b[0m     X,\n\u001b[0;32m    846\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    847\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    848\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    849\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_call,\n\u001b[0;32m    850\u001b[0m )\n\u001b[0;32m    851\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    853\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'fixed acidity'"
     ]
    }
   ],
   "source": [
    "#Normalização das características\n",
    "X_train = norm.fit_transform(X_train)\n",
    "X_test = norm.fit_transform(X_test)\n",
    "X_val = norm.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.36832844  0.70376003 -0.32100428 -0.17817278 -0.26931748  1.43977149\n",
      "  2.65375455 -0.60760869 -0.22487088 -1.1488296  -0.42572627]\n",
      "\n",
      "['7.8' '0.53' '0.01' '1.6' '0.077' '3' '19' '0.995' '3.16' '0.46' '9.8']\n",
      "\n",
      "['fixed acidity' 'volatile acidity' 'citric acid' 'residual sugar'\n",
      " 'chlorides' 'free sulfur dioxide' 'total sulfur dioxide' 'density' 'pH'\n",
      " 'sulphates' 'alcohol']\n"
     ]
    }
   ],
   "source": [
    "#checando a parte de dados normalizados \n",
    "print(X_train[0],\n",
    "        X_val[0],\n",
    "        X_test[0],\n",
    "        sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAÁRIAVEIS \"DUMMIES\" PARA TRATAMENTO DE DADOS CATEGORICOS NOMINAIS\n",
    "Algumas variáveis no conjunto de dados são discretas nominais, ou seja, os valores apresentados não representam uma contagem ordinal, mas categorias. Essa situação também pode gerar inconsistências na criação e treinamento de modelos. Para lidar com essa situação serão criadas variáveis dummies, ou seja, variáveis que representam cada categoria e assumem valores binárias (1 = verdadeiro / 0 = falso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conferindo os valores da variavel fixed acidity\n",
    "print(data_train['fixed acidity'].head(10),\n",
    "        data_train['fixed acidity'].describe(),\n",
    "        sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coferindo os valores possíveis da variavel\n",
    "set(data_train['fixed acidity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebemos pala analise que as opções de valores para fixed acidity estão registradas na base de dados com os valores []. Para criação de variaveis *dummines* serão criadas $n-1$ variaveis binárias, onde $n$ é o número de categorias. Isso é feito porque a categoria $n$ ocorrerá quando todas as demais tiveram valor 0 e, portanto, não precise ser mapeada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para exemplificar a lógica consideremos fixed acidity cuja categoria é 0. podemos consultar o dataframe original da forma abaixo e obtemos um vetor de valores lógicos, na qual é apontado verdadeiro para os casos emq ue a categoria do fixed acidity é 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['fixed acidity'] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_acidity_0 = (data_train['fixed acidity'] ==0)\n",
    "fixed_acidity_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para criar as variaveis, basta usar esta mesma lógica para as categorias desejadas, transformando os valores lógicos em inteiros. Contudo, a biblioteca pandas possui um método get_dummies que simplemente transforma. Aplicaremos abaixo o método no conjuto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(data = data_train,\n",
    "                prefix='fa',\n",
    "                columns=['fixed acidity'],\n",
    "                drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que o atributo 'fixed acidity' foi substituído pelas variáveis novas e criado um data frame com os dados originais, exceto por esta substituição. Além disso, veja que foi definido o parâmetro drop_first com valor True, isso força o método a eliminar a primeira categoria, tornando a quantidade de dummies igual a $n-1$ pelos motivos explicados anteriormente nessa seção. Caso queira que todas as categorias estejam presentes no novo data frame, o parâmetro drop_first deve ser descartado, tendo em vista que seu valor padrão é False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usando a lógica estado para recarregar os dados e refazer a separação\n",
    "data_train_ = pd.get_dummies(data = data_train,\n",
    "                prefix='fa',\n",
    "                columns=['fixed acidity'],\n",
    "                drop_first=False)\n",
    "data_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_ = pd.get_dummies(data = data_test,\n",
    "                prefix='fa',\n",
    "                columns=['fixed acidity'],\n",
    "                drop_first=False)\n",
    "data_test_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separação da variavel algo não mudo \n",
    "#-----------------------------------\n",
    "\n",
    "#Transoformação dos atributos e da classe alvo em matrizes \n",
    "y_train_ = np.array(data_train['quality'])\n",
    "\n",
    "#Transformação dos atributos e da classe alvo em matriz\n",
    "y_test = np.array(data_test['quality'])\n",
    "\n",
    "#varificando \n",
    "print(y_train_[:10],\n",
    "        y_test[:10],\n",
    "        sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando os atributos precisa atentar que não preservada a ordem das colunas\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "#Recuperação dos nomes das colunas \n",
    "atributos = list(data_train_.columns)\n",
    "\n",
    "#verificando \n",
    "atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'eliminidando as colunas com a classe na lista de atributos'\n",
    "atributos.remove('quality')\n",
    "\n",
    "#verificando \n",
    "atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conferindo o uso da lista de atributos para separação do conjunto de dados \n",
    "data_train_.loc[:, atributos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Uso da lista de atributos para separação do conjunto de dados\n",
    "\n",
    "#Transoformação dos atributos e da classe alvo em matrizes\n",
    "X_train_ = np.array(data_train_.loc[:, atributos])\n",
    "\n",
    "#Transformação dos atributos e da classe alvo em matrizes\n",
    "X_test = np.array(data_test_.loc[:, atributos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separação de treino e validação não muda\n",
    "##=======================================\n",
    "\n",
    "#Separação de treino e validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_, y_train_,\n",
    "                                                  train_size=0.8,\n",
    "                                                  random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Checagem rápida de parte dos dados carregados\n",
    "print(X_train[:5],\n",
    "      X_val[:5],\n",
    "      X_test[:5],\n",
    "      sep='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82426e9ecc58341f1ef8e214ae82fe6c690940504c0647c777d68997be611dce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
